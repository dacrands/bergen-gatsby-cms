---
templateKey: projectTemplate
title: Mainframe Medical Database
image: /img/mainframemedicaldatabasecover.jpg
abstract: >-
  The purpose of this project is to create a medical database within a mainframe
  environment. In order to accomplish this task, we will be gathering readily
  available data from government regulated websites. This data must be in the
  form of a .CSV file, and will be transferred to a mainframe environment
  through FTP. Meanwhile, we will simultaneously be creating a logical model of
  our database using ERwin Data Modeling software.  From here we will use DDL to
  create a DB2 mainframe database to store our acquired data. Finally, we will
  use SQL queries to analyze this database to look for interesting trends,
  patterns, and statistics, and ultimately use FTP to bring those results out of
  the mainframe environment into a user-friendly “front-end” software.
meeting: 'Monday-Thursday 10:00am-12:00pm / 1:00pm-3:00pm in room S-243'
students:
  - email: tzamski@me.bergen.edu
    name: 'Tyler Zamski '
  - email: rel-saleh@me.bergen.edu
    name: Ramya El-Saleh
  - email: agonzalez114138@me.bergen.edu
    name: 'Andres Gonzalez '
  - email: mhernandez113775@me.bergen.edu
    name: Michael Hernandez
  - email: cmooney@me.bergen.edu
    name: Caitlin Mooney
mentors:
  - email: aeliscu@bergen.edu
    name: Professor Alan S. Eliscu
blog:
  - body: "_Ramya El-Saleh_ \n\nIntroduced to the basic concept of data analytics using mainframe and Extract Transform Load (ETL) data integration as well as the projects vision and mission.\r\n\nSearched and gathered EMR (Electronic Medical Records). Learned the process required to request large medical databases offered specifically for researchers by a variety of national medical societies and institutions.\r\n\n\n\n_Andres Gonzalez_\n\nUsing available material and parts we needed to find a solution to the logistical problem of working with large files in a limited network with no centralization. Thus we created LOLA (Logistical Output Load Array) which serves both as a VM server ( Linux, Windows, Android, Mac OS, etc) and as a network driver where we centralize all out work, keep it updated easily and back it up.\r\n\n\n\n_Michael Hernandez_ \n\nLearning the basics of the ETL process, and database architecture from Professor Eliscu. This is with the prospect of organizing data that could have a parallel key made, when loaded into the mainframe for queries. The organization of the data, however, is a greater workload than the physical formatting, because of the size of our data and being able to properly identify important data involving biometrics. \n\n\n\n_Caitlin Mooney_\n\nContinued prior research, looking for relevant and usable data files.  Researched options for the ETL process and for data analysis, with the aim to automate both the file transfer on and off the mainframe, as well as the data organization. The best possible option being a program called Tableau, as it has compatibility with the mainframe and file transfer ability for DB2 databases, as well as the IBM Cloud platform.\r\n\n\n\n_Tyler Zamski_\n\nAnd so it begins! This week we began organizing our workflow and planning our research process. We consolidated our previously found data in a single save location within LOLA, as well as determined what additional data we would need. We found several holes within our process, and began to explore alternative solutions. Specifically, we needed to find better data files to work with that could produce the type database we hoped to build."
    date: 2019-06-04T00:41:38.244Z
    title: Week 1
    image: /img/mdb-week-0.jpg
---

